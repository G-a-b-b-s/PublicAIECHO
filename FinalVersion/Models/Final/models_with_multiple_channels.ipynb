{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T05:50:35.214950Z",
     "start_time": "2025-04-14T05:47:30.221856Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install timm",
   "id": "37e327142ee2a7ca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "f55fc18d-beae-4ec0-9b14-2b72520b800f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T05:55:20.758589Z",
     "start_time": "2025-04-14T05:55:14.460423Z"
    }
   },
   "source": [
    "# https://towardsdatascience.com/getting-started-with-pytorch-image-models-timm-a-practitioners-guide-4e77b4bf9055-2/\n",
    "# https://github.com/huggingface/pytorch-image-models/tree/main?tab=readme-ov-file\n",
    "# https://huggingface.co/docs/hub/timm\n",
    "\n",
    "# import logging\n",
    "# import os\n",
    "# import string\n",
    "# import sys\n",
    "# import nibabel as nib\n",
    "# import random\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import seaborn as sns\n",
    "# from matplotlib import pyplot as plt\n",
    "# from sklearn.utils import compute_class_weight\n",
    "# from torch import nn\n",
    "# from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# from torch.optim import Adam\n",
    "# from torchvision.models import resnet18, efficientnet_b0\n",
    "# from torchvision.transforms import Compose, ToTensor, Normalize, Resize, Pad, RandomHorizontalFlip, RandomVerticalFlip, \\\n",
    "#     RandomRotation, InterpolationMode\n",
    "# from torch.utils.data import WeightedRandomSampler\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
    "# \n",
    "# ############################################################\n",
    "# \n",
    "# from densenet2d import *\n",
    "# \n",
    "# ############################################################\n",
    "\n",
    "import timm\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\48735\\Desktop\\AGH\\AI_ECHO\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "41790656-80e0-4bb4-b98b-a90ab03c2fe4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T05:55:26.016903Z",
     "start_time": "2025-04-14T05:55:25.999662Z"
    }
   },
   "source": "timm.list_models('*vit*')",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['convit_base',\n",
       " 'convit_small',\n",
       " 'convit_tiny',\n",
       " 'crossvit_9_240',\n",
       " 'crossvit_9_dagger_240',\n",
       " 'crossvit_15_240',\n",
       " 'crossvit_15_dagger_240',\n",
       " 'crossvit_15_dagger_408',\n",
       " 'crossvit_18_240',\n",
       " 'crossvit_18_dagger_240',\n",
       " 'crossvit_18_dagger_408',\n",
       " 'crossvit_base_240',\n",
       " 'crossvit_small_240',\n",
       " 'crossvit_tiny_240',\n",
       " 'davit_base',\n",
       " 'davit_base_fl',\n",
       " 'davit_giant',\n",
       " 'davit_huge',\n",
       " 'davit_huge_fl',\n",
       " 'davit_large',\n",
       " 'davit_small',\n",
       " 'davit_tiny',\n",
       " 'efficientvit_b0',\n",
       " 'efficientvit_b1',\n",
       " 'efficientvit_b2',\n",
       " 'efficientvit_b3',\n",
       " 'efficientvit_l1',\n",
       " 'efficientvit_l2',\n",
       " 'efficientvit_l3',\n",
       " 'efficientvit_m0',\n",
       " 'efficientvit_m1',\n",
       " 'efficientvit_m2',\n",
       " 'efficientvit_m3',\n",
       " 'efficientvit_m4',\n",
       " 'efficientvit_m5',\n",
       " 'fastvit_ma36',\n",
       " 'fastvit_mci0',\n",
       " 'fastvit_mci1',\n",
       " 'fastvit_mci2',\n",
       " 'fastvit_s12',\n",
       " 'fastvit_sa12',\n",
       " 'fastvit_sa24',\n",
       " 'fastvit_sa36',\n",
       " 'fastvit_t8',\n",
       " 'fastvit_t12',\n",
       " 'flexivit_base',\n",
       " 'flexivit_large',\n",
       " 'flexivit_small',\n",
       " 'gcvit_base',\n",
       " 'gcvit_small',\n",
       " 'gcvit_tiny',\n",
       " 'gcvit_xtiny',\n",
       " 'gcvit_xxtiny',\n",
       " 'levit_128',\n",
       " 'levit_128s',\n",
       " 'levit_192',\n",
       " 'levit_256',\n",
       " 'levit_256d',\n",
       " 'levit_384',\n",
       " 'levit_384_s8',\n",
       " 'levit_512',\n",
       " 'levit_512_s8',\n",
       " 'levit_512d',\n",
       " 'levit_conv_128',\n",
       " 'levit_conv_128s',\n",
       " 'levit_conv_192',\n",
       " 'levit_conv_256',\n",
       " 'levit_conv_256d',\n",
       " 'levit_conv_384',\n",
       " 'levit_conv_384_s8',\n",
       " 'levit_conv_512',\n",
       " 'levit_conv_512_s8',\n",
       " 'levit_conv_512d',\n",
       " 'maxvit_base_tf_224',\n",
       " 'maxvit_base_tf_384',\n",
       " 'maxvit_base_tf_512',\n",
       " 'maxvit_large_tf_224',\n",
       " 'maxvit_large_tf_384',\n",
       " 'maxvit_large_tf_512',\n",
       " 'maxvit_nano_rw_256',\n",
       " 'maxvit_pico_rw_256',\n",
       " 'maxvit_rmlp_base_rw_224',\n",
       " 'maxvit_rmlp_base_rw_384',\n",
       " 'maxvit_rmlp_nano_rw_256',\n",
       " 'maxvit_rmlp_pico_rw_256',\n",
       " 'maxvit_rmlp_small_rw_224',\n",
       " 'maxvit_rmlp_small_rw_256',\n",
       " 'maxvit_rmlp_tiny_rw_256',\n",
       " 'maxvit_small_tf_224',\n",
       " 'maxvit_small_tf_384',\n",
       " 'maxvit_small_tf_512',\n",
       " 'maxvit_tiny_pm_256',\n",
       " 'maxvit_tiny_rw_224',\n",
       " 'maxvit_tiny_rw_256',\n",
       " 'maxvit_tiny_tf_224',\n",
       " 'maxvit_tiny_tf_384',\n",
       " 'maxvit_tiny_tf_512',\n",
       " 'maxvit_xlarge_tf_224',\n",
       " 'maxvit_xlarge_tf_384',\n",
       " 'maxvit_xlarge_tf_512',\n",
       " 'maxxvit_rmlp_nano_rw_256',\n",
       " 'maxxvit_rmlp_small_rw_256',\n",
       " 'maxxvit_rmlp_tiny_rw_256',\n",
       " 'maxxvitv2_nano_rw_256',\n",
       " 'maxxvitv2_rmlp_base_rw_224',\n",
       " 'maxxvitv2_rmlp_base_rw_384',\n",
       " 'maxxvitv2_rmlp_large_rw_224',\n",
       " 'mobilevit_s',\n",
       " 'mobilevit_xs',\n",
       " 'mobilevit_xxs',\n",
       " 'mobilevitv2_050',\n",
       " 'mobilevitv2_075',\n",
       " 'mobilevitv2_100',\n",
       " 'mobilevitv2_125',\n",
       " 'mobilevitv2_150',\n",
       " 'mobilevitv2_175',\n",
       " 'mobilevitv2_200',\n",
       " 'mvitv2_base',\n",
       " 'mvitv2_base_cls',\n",
       " 'mvitv2_huge_cls',\n",
       " 'mvitv2_large',\n",
       " 'mvitv2_large_cls',\n",
       " 'mvitv2_small',\n",
       " 'mvitv2_small_cls',\n",
       " 'mvitv2_tiny',\n",
       " 'nextvit_base',\n",
       " 'nextvit_large',\n",
       " 'nextvit_small',\n",
       " 'repvit_m0_9',\n",
       " 'repvit_m1',\n",
       " 'repvit_m1_0',\n",
       " 'repvit_m1_1',\n",
       " 'repvit_m1_5',\n",
       " 'repvit_m2',\n",
       " 'repvit_m2_3',\n",
       " 'repvit_m3',\n",
       " 'samvit_base_patch16',\n",
       " 'samvit_base_patch16_224',\n",
       " 'samvit_huge_patch16',\n",
       " 'samvit_large_patch16',\n",
       " 'test_vit',\n",
       " 'test_vit2',\n",
       " 'test_vit3',\n",
       " 'test_vit4',\n",
       " 'tiny_vit_5m_224',\n",
       " 'tiny_vit_11m_224',\n",
       " 'tiny_vit_21m_224',\n",
       " 'tiny_vit_21m_384',\n",
       " 'tiny_vit_21m_512',\n",
       " 'vit_base_mci_224',\n",
       " 'vit_base_patch8_224',\n",
       " 'vit_base_patch14_dinov2',\n",
       " 'vit_base_patch14_reg4_dinov2',\n",
       " 'vit_base_patch16_18x2_224',\n",
       " 'vit_base_patch16_224',\n",
       " 'vit_base_patch16_224_miil',\n",
       " 'vit_base_patch16_384',\n",
       " 'vit_base_patch16_clip_224',\n",
       " 'vit_base_patch16_clip_384',\n",
       " 'vit_base_patch16_clip_quickgelu_224',\n",
       " 'vit_base_patch16_gap_224',\n",
       " 'vit_base_patch16_plus_240',\n",
       " 'vit_base_patch16_plus_clip_240',\n",
       " 'vit_base_patch16_reg4_gap_256',\n",
       " 'vit_base_patch16_rope_reg1_gap_256',\n",
       " 'vit_base_patch16_rpn_224',\n",
       " 'vit_base_patch16_siglip_224',\n",
       " 'vit_base_patch16_siglip_256',\n",
       " 'vit_base_patch16_siglip_384',\n",
       " 'vit_base_patch16_siglip_512',\n",
       " 'vit_base_patch16_siglip_gap_224',\n",
       " 'vit_base_patch16_siglip_gap_256',\n",
       " 'vit_base_patch16_siglip_gap_384',\n",
       " 'vit_base_patch16_siglip_gap_512',\n",
       " 'vit_base_patch16_xp_224',\n",
       " 'vit_base_patch32_224',\n",
       " 'vit_base_patch32_384',\n",
       " 'vit_base_patch32_clip_224',\n",
       " 'vit_base_patch32_clip_256',\n",
       " 'vit_base_patch32_clip_384',\n",
       " 'vit_base_patch32_clip_448',\n",
       " 'vit_base_patch32_clip_quickgelu_224',\n",
       " 'vit_base_patch32_plus_256',\n",
       " 'vit_base_patch32_siglip_256',\n",
       " 'vit_base_patch32_siglip_gap_256',\n",
       " 'vit_base_r26_s32_224',\n",
       " 'vit_base_r50_s16_224',\n",
       " 'vit_base_r50_s16_384',\n",
       " 'vit_base_resnet26d_224',\n",
       " 'vit_base_resnet50d_224',\n",
       " 'vit_betwixt_patch16_gap_256',\n",
       " 'vit_betwixt_patch16_reg1_gap_256',\n",
       " 'vit_betwixt_patch16_reg4_gap_256',\n",
       " 'vit_betwixt_patch16_reg4_gap_384',\n",
       " 'vit_betwixt_patch16_rope_reg4_gap_256',\n",
       " 'vit_betwixt_patch32_clip_224',\n",
       " 'vit_giant_patch14_224',\n",
       " 'vit_giant_patch14_clip_224',\n",
       " 'vit_giant_patch14_dinov2',\n",
       " 'vit_giant_patch14_reg4_dinov2',\n",
       " 'vit_giant_patch16_gap_224',\n",
       " 'vit_giantopt_patch16_siglip_256',\n",
       " 'vit_giantopt_patch16_siglip_384',\n",
       " 'vit_giantopt_patch16_siglip_gap_256',\n",
       " 'vit_giantopt_patch16_siglip_gap_384',\n",
       " 'vit_gigantic_patch14_224',\n",
       " 'vit_gigantic_patch14_clip_224',\n",
       " 'vit_gigantic_patch14_clip_quickgelu_224',\n",
       " 'vit_huge_patch14_224',\n",
       " 'vit_huge_patch14_clip_224',\n",
       " 'vit_huge_patch14_clip_336',\n",
       " 'vit_huge_patch14_clip_378',\n",
       " 'vit_huge_patch14_clip_quickgelu_224',\n",
       " 'vit_huge_patch14_clip_quickgelu_378',\n",
       " 'vit_huge_patch14_gap_224',\n",
       " 'vit_huge_patch14_xp_224',\n",
       " 'vit_huge_patch16_gap_448',\n",
       " 'vit_intern300m_patch14_448',\n",
       " 'vit_large_patch14_224',\n",
       " 'vit_large_patch14_clip_224',\n",
       " 'vit_large_patch14_clip_336',\n",
       " 'vit_large_patch14_clip_quickgelu_224',\n",
       " 'vit_large_patch14_clip_quickgelu_336',\n",
       " 'vit_large_patch14_dinov2',\n",
       " 'vit_large_patch14_reg4_dinov2',\n",
       " 'vit_large_patch14_xp_224',\n",
       " 'vit_large_patch16_224',\n",
       " 'vit_large_patch16_384',\n",
       " 'vit_large_patch16_siglip_256',\n",
       " 'vit_large_patch16_siglip_384',\n",
       " 'vit_large_patch16_siglip_512',\n",
       " 'vit_large_patch16_siglip_gap_256',\n",
       " 'vit_large_patch16_siglip_gap_384',\n",
       " 'vit_large_patch16_siglip_gap_512',\n",
       " 'vit_large_patch32_224',\n",
       " 'vit_large_patch32_384',\n",
       " 'vit_large_r50_s32_224',\n",
       " 'vit_large_r50_s32_384',\n",
       " 'vit_little_patch16_reg1_gap_256',\n",
       " 'vit_little_patch16_reg4_gap_256',\n",
       " 'vit_medium_patch16_clip_224',\n",
       " 'vit_medium_patch16_gap_240',\n",
       " 'vit_medium_patch16_gap_256',\n",
       " 'vit_medium_patch16_gap_384',\n",
       " 'vit_medium_patch16_reg1_gap_256',\n",
       " 'vit_medium_patch16_reg4_gap_256',\n",
       " 'vit_medium_patch16_rope_reg1_gap_256',\n",
       " 'vit_medium_patch32_clip_224',\n",
       " 'vit_mediumd_patch16_reg4_gap_256',\n",
       " 'vit_mediumd_patch16_reg4_gap_384',\n",
       " 'vit_mediumd_patch16_rope_reg1_gap_256',\n",
       " 'vit_pwee_patch16_reg1_gap_256',\n",
       " 'vit_relpos_base_patch16_224',\n",
       " 'vit_relpos_base_patch16_cls_224',\n",
       " 'vit_relpos_base_patch16_clsgap_224',\n",
       " 'vit_relpos_base_patch16_plus_240',\n",
       " 'vit_relpos_base_patch16_rpn_224',\n",
       " 'vit_relpos_base_patch32_plus_rpn_256',\n",
       " 'vit_relpos_medium_patch16_224',\n",
       " 'vit_relpos_medium_patch16_cls_224',\n",
       " 'vit_relpos_medium_patch16_rpn_224',\n",
       " 'vit_relpos_small_patch16_224',\n",
       " 'vit_relpos_small_patch16_rpn_224',\n",
       " 'vit_small_patch8_224',\n",
       " 'vit_small_patch14_dinov2',\n",
       " 'vit_small_patch14_reg4_dinov2',\n",
       " 'vit_small_patch16_18x2_224',\n",
       " 'vit_small_patch16_36x1_224',\n",
       " 'vit_small_patch16_224',\n",
       " 'vit_small_patch16_384',\n",
       " 'vit_small_patch32_224',\n",
       " 'vit_small_patch32_384',\n",
       " 'vit_small_r26_s32_224',\n",
       " 'vit_small_r26_s32_384',\n",
       " 'vit_small_resnet26d_224',\n",
       " 'vit_small_resnet50d_s16_224',\n",
       " 'vit_so150m2_patch16_reg1_gap_256',\n",
       " 'vit_so150m2_patch16_reg1_gap_384',\n",
       " 'vit_so150m2_patch16_reg1_gap_448',\n",
       " 'vit_so150m_patch16_reg4_gap_256',\n",
       " 'vit_so150m_patch16_reg4_gap_384',\n",
       " 'vit_so150m_patch16_reg4_map_256',\n",
       " 'vit_so400m_patch14_siglip_224',\n",
       " 'vit_so400m_patch14_siglip_378',\n",
       " 'vit_so400m_patch14_siglip_384',\n",
       " 'vit_so400m_patch14_siglip_gap_224',\n",
       " 'vit_so400m_patch14_siglip_gap_378',\n",
       " 'vit_so400m_patch14_siglip_gap_384',\n",
       " 'vit_so400m_patch14_siglip_gap_448',\n",
       " 'vit_so400m_patch14_siglip_gap_896',\n",
       " 'vit_so400m_patch16_siglip_256',\n",
       " 'vit_so400m_patch16_siglip_384',\n",
       " 'vit_so400m_patch16_siglip_512',\n",
       " 'vit_so400m_patch16_siglip_gap_256',\n",
       " 'vit_so400m_patch16_siglip_gap_384',\n",
       " 'vit_so400m_patch16_siglip_gap_512',\n",
       " 'vit_srelpos_medium_patch16_224',\n",
       " 'vit_srelpos_small_patch16_224',\n",
       " 'vit_tiny_patch16_224',\n",
       " 'vit_tiny_patch16_384',\n",
       " 'vit_tiny_r_s16_p8_224',\n",
       " 'vit_tiny_r_s16_p8_384',\n",
       " 'vit_wee_patch16_reg1_gap_256',\n",
       " 'vit_xsmall_patch16_clip_224',\n",
       " 'vitamin_base_224',\n",
       " 'vitamin_large2_224',\n",
       " 'vitamin_large2_256',\n",
       " 'vitamin_large2_336',\n",
       " 'vitamin_large2_384',\n",
       " 'vitamin_large_224',\n",
       " 'vitamin_large_256',\n",
       " 'vitamin_large_336',\n",
       " 'vitamin_large_384',\n",
       " 'vitamin_small_224',\n",
       " 'vitamin_xlarge_256',\n",
       " 'vitamin_xlarge_336',\n",
       " 'vitamin_xlarge_384']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 2,
   "source": [
    "\n",
    "#####################################################\n",
    "# configs\n",
    "#####################################################\n",
    "\n",
    "dataset_dir = \"./DATA/\"\n",
    "\n",
    "# class weights must be inversely poropotrional to the class counts\n",
    "class_weights = {0:4, 1:1, 2:1, 3:5}\n",
    "\n",
    "# input image sizes\n",
    "W = 678\n",
    "H = 850\n",
    "\n",
    "# Po przerobieniu danych W i H należy zastapić tymi wartościami\n",
    "# W = 590\n",
    "# H = 830\n",
    "PADD = (0, (H-W)//2)\n",
    "\n",
    "# range for degrees of random rotations\n",
    "DEGREES = 90\n"
   ],
   "id": "a30b0387-fba6-4450-aec4-37ecdc127c3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 3,
   "source": [
    "#####################################################\n",
    "# dataloaders \n",
    "#####################################################\n",
    "\n",
    "train_data, test_data, train_weights, _ = load_dataset(dataset_dir, class_weights)\n",
    "\n",
    "train_transforms = Compose([\n",
    "    ToTensor(),\n",
    "    Pad(PADD),\n",
    "    RandomHorizontalFlip(),\n",
    "    RandomVerticalFlip(),\n",
    "    RandomRotation(DEGREES, InterpolationMode.BILINEAR),\n",
    "    Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "test_transforms = Compose([\n",
    "    ToTensor(),\n",
    "    Pad(PADD),\n",
    "    Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "trainSampler = WeightedRandomSampler(train_weights, len(train_weights),replacement=True)\n",
    "train_ds = CustomDataset(data=train_data, transform=train_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=1, sampler=trainSampler, num_workers=4)\n",
    "\n",
    "test_ds = CustomDataset(data=test_data, transform=test_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, shuffle = False, num_workers=4)\n"
   ],
   "id": "4f090bc4-a052-4215-88a1-a4db7ed0847e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 30, 850, 850]) tensor([3])\n",
      "torch.Size([1, 30, 850, 850]) tensor([3])\n",
      "torch.Size([1, 30, 850, 850]) tensor([3])\n",
      "torch.Size([1, 30, 850, 850]) tensor([2])\n",
      "torch.Size([1, 30, 850, 850]) tensor([0])\n",
      "torch.Size([1, 30, 850, 850]) tensor([3])\n"
     ]
    }
   ],
   "execution_count": 4,
   "source": [
    "for n, (imgs, labels) in enumerate(train_loader):\n",
    "    print(imgs.shape,labels)\n",
    "    if n==5:\n",
    "        break"
   ],
   "id": "89ef0be2-e331-434b-b7a1-d4a08779754b"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3055078-8cfe-4067-96e7-00543932b236",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "custom_model = densenet161(input_channels = 30,num_classes=4)\n",
    "\n",
    "resnet_timm_model = timm.create_model('resnet50d', pretrained=True, in_chans = 30, num_classes = 4)\n",
    "\n",
    "efficient_timm_model = timm.create_model('efficientnet_b0', pretrained=True, in_chans = 30, num_classes = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a256c391-efb0-425a-ba12-2b052bb27aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 30, 850, 850]) tensor([2])\n",
      "tensor([[-0.0551,  0.1659, -0.1007, -0.2479]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.0727,  0.0010, -0.0718, -0.0414]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 1.1143, -0.8841,  1.3331, -2.9833]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ": this = 0x6022ce4142d0, size = (850,850,30,1) [82 Mio], data = (float32*)0x7d461a600010..0x7d461f8aefef (non-shared) = [ -1 -1 -1 -1 -1 -1 -1 -1 ... -1 -1 -1 -1 -1 -1 -1 -1 ], min = -1, max = 471.961, mean = 31.7059, std = 73.3285, coords_min = (0,0,0,0), coords_max = (341,378,22,0).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training time\n",
    "\n",
    "for imgs, labels in train_loader:\n",
    "    print(imgs.shape,labels)\n",
    "    out1 = custom_model(imgs)\n",
    "    out2 = resnet_timm_model(imgs)\n",
    "    out3 = efficient_timm_model(imgs)\n",
    "    print(out1)\n",
    "    print(out2)\n",
    "    print(out3)\n",
    "    CImg(imgs.detach().cpu().numpy()).display();\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dee41d07-c326-43c8-9c8d-117b9a3b8e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 30, 850, 850]) tensor([2])\n",
      "tensor([[ 0.2434,  0.6755, -0.6558, -0.7655]])\n",
      "tensor([[-0.0678, -0.0181, -0.0512,  0.1313]])\n",
      "tensor([[ 9.5248,  2.0851,  5.4184, -6.7913]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ": this = 0x60225b4b8700, size = (850,850,30,1) [82 Mio], data = (float32*)0x6022ba118b80..0x6022bf3c7b5f (non-shared) = [ -1 -1 -1 -1 -1 -1 -1 -1 ... -1 -1 -1 -1 -1 -1 -1 -1 ], min = -1, max = 485, mean = 27.7924, std = 65.1237, coords_min = (0,0,0,0), coords_max = (317,621,24,0).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Testing time\n",
    "\n",
    "custom_model.eval()\n",
    "resnet_timm_model.eval()\n",
    "efficient_timm_model.eval()\n",
    "\n",
    "for imgs, labels in test_loader:\n",
    "    print(imgs.shape,labels)\n",
    "    with torch.no_grad():\n",
    "        out1 = custom_model(imgs)\n",
    "        out2 = resnet_timm_model(imgs)\n",
    "        out3 = efficient_timm_model(imgs)\n",
    "    print(out1)\n",
    "    print(out2)\n",
    "    print(out3)\n",
    "    CImg(imgs.detach().cpu().numpy()).display();\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
